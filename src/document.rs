use crate::cleaner::DocumentCleaner;
use crate::config::ProcessingConfig;
use crate::error::{Result, SmartFetchError};
use std::fs;
use std::path::{Path, PathBuf};
use tracing_indicatif::indicatif_println;

#[derive(Debug, Clone)]
pub struct Document {
    pub path: PathBuf,
    pub content: String,
    pub content_type: String,
    pub size_bytes: usize,
    pub metadata: DocumentMetadata,
}

#[derive(Debug, Clone, Default)]
pub struct DocumentMetadata {
    pub title: Option<String>,
    pub author: Option<String>,
    pub created_at: Option<String>,
    pub modified_at: Option<String>,
    pub word_count: usize,
    pub line_count: usize,
}

pub struct DocumentProcessor {
    config: ProcessingConfig,
    cleaner: Option<DocumentCleaner>,
}

impl DocumentProcessor {
    #[tracing::instrument(level = "debug", skip(config), name = "åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨")]
    pub fn new(config: ProcessingConfig) -> Result<Self> {
        let cleaner = if let Some(cleaning_config) = &config.cleaning {
            if cleaning_config.enable_cleaning.unwrap_or(false) {
                Some(DocumentCleaner::new(cleaning_config.clone())?)
            } else {
                None
            }
        } else {
            None
        };

        Ok(Self {
            config,
            cleaner,
        })
    }

    #[tracing::instrument(level = "info", skip(self), name = "åŠ è½½æ–‡æ¡£æ–‡ä»¶")]
    pub async fn load_document(&self, path: &Path) -> Result<Document> {
        if !path.exists() {
            return Err(SmartFetchError::DocumentError(format!(
                "æ–‡ä»¶ä¸å­˜åœ¨: {:?}",
                path
            )));
        }

        let _file_name = path.file_name()
            .and_then(|name| name.to_str())
            .unwrap_or("æœªçŸ¥æ–‡ä»¶");

        let metadata = fs::metadata(path)
            .map_err(|e| SmartFetchError::DocumentError(format!("æ— æ³•è¯»å–æ–‡ä»¶å…ƒæ•°æ®: {}", e)))?;

        if metadata.len() > (10 * 1024 * 1024) {
            return Err(SmartFetchError::DocumentError(
                "æ–‡ä»¶å¤§å°è¶…è¿‡10MBé™åˆ¶".to_string(),
            ));
        }

        let content = fs::read_to_string(path)
            .map_err(|e| SmartFetchError::DocumentError(format!("æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹: {}", e)))?;

        let content_type = Self::detect_content_type(path)?;
        let document_metadata = Self::extract_metadata(&content);

        // æ·»åŠ æ–‡æ¡£åŠ è½½å®Œæˆæç¤º
        indicatif_println!("âœ… æ–‡æ¡£åŠ è½½æˆåŠŸ: {} ({} å­—ç¬¦)",
            path.file_name().and_then(|name| name.to_str()).unwrap_or("æœªçŸ¥æ–‡ä»¶"),
            content.len());

        Ok(Document {
            path: path.to_path_buf(),
            content,
            content_type,
            size_bytes: metadata.len() as usize,
            metadata: document_metadata,
        })
    }

    pub fn detect_content_type(path: &Path) -> Result<String> {
        let extension = path.extension().and_then(|ext| ext.to_str()).unwrap_or("");

        match extension.to_lowercase().as_str() {
            "txt" => Ok("text/plain".to_string()),
            "md" => Ok("text/markdown".to_string()),
            "json" => Ok("application/json".to_string()),
            "yaml" | "yml" => Ok("text/yaml".to_string()),
            "toml" => Ok("text/toml".to_string()),
            "xml" => Ok("application/xml".to_string()),
            "csv" => Ok("text/csv".to_string()),
            _ => Ok("text/plain".to_string()),
        }
    }

    pub fn extract_metadata(content: &str) -> DocumentMetadata {
        let word_count = content.split_whitespace().count();
        let line_count = content.lines().count();

        // å°è¯•ä»Markdownæ–‡ä»¶ä¸­æå–æ ‡é¢˜
        let title = content
            .lines()
            .find(|line| line.starts_with('#'))
            .map(|line| line.trim_start_matches('#').trim().to_string());

        DocumentMetadata {
            title,
            author: None,
            created_at: None,
            modified_at: None,
            word_count,
            line_count,
        }
    }

    #[tracing::instrument(level = "debug", skip(self, content), name = "é¢„å¤„ç†æ–‡æ¡£å†…å®¹")]
    pub fn preprocess_content(&self, content: &str) -> Result<String> {
        if !self.config.enable_preprocessing.unwrap_or(true) {
            return Ok(content.to_string());
        }

        // é¢„å¤„ç†æ–‡æ¡£å†…å®¹

        let mut processed = content.to_string();

        // ç¬¬ä¸€æ­¥ï¼šæ–‡æ¡£æ¸…ç†
        if let Some(cleaner) = &self.cleaner {
            // pb.set_message("ğŸ§¹ æ¸…ç†æ–‡æ¡£å†…å®¹...");
            processed = cleaner.clean_content(&processed)?;
            // pb.set_position((content.len() / 4) as u64);
        }

        // ç¬¬äºŒæ­¥ï¼šç§»é™¤å¤šä½™çš„ç©ºè¡Œ
        // pb.set_message("ğŸ”§ ç§»é™¤å¤šä½™ç©ºè¡Œ...");
        processed = processed
            .lines()
            .filter(|line| !line.trim().is_empty())
            .collect::<Vec<_>>()
            .join("\n\n");
        // pb.set_position((content.len() / 2) as u64);

        // ç¬¬ä¸‰æ­¥ï¼šæ¸…ç†ç‰¹æ®Šå­—ç¬¦
        // pb.set_message("ğŸ”§ æ¸…ç†ç‰¹æ®Šå­—ç¬¦...");
        processed = processed.replace("\r\n", "\n");
        processed = processed.replace('\t', "    ");
        // pb.set_position((content.len() * 3 / 4) as u64);

        // ç¬¬å››æ­¥ï¼šç§»é™¤BOMæ ‡è®°
        if processed.starts_with('\u{FEFF}') {
            // pb.set_message("ğŸ”§ ç§»é™¤BOMæ ‡è®°...");
            processed = processed[3..].to_string();
        }

        // æ·»åŠ é¢„å¤„ç†å®Œæˆæç¤º
        let size_reduction = if content.len() > processed.len() {
            format!(" (å‹ç¼©äº†{}å­—ç¬¦)", content.len() - processed.len())
        } else {
            String::new()
        };
        indicatif_println!("âœ… é¢„å¤„ç†å®Œæˆ{}", size_reduction);

        Ok(processed)
    }

    #[tracing::instrument(level = "debug", skip(self, content), name = "åˆ†å—å¤„ç†æ–‡æ¡£")]
    pub fn chunk_content(&self, content: &str) -> Result<Vec<String>> {
        let chunk_size = self.config.chunk_size.unwrap_or(4000);

        if content.len() <= chunk_size {
            return Ok(vec![content.to_string()]);
        }

        // åˆ†å—å¤„ç†é•¿æ–‡æ¡£

        let mut chunks = Vec::new();
        let mut start = 0;

        while start < content.len() {
            let end = (start + chunk_size).min(content.len());

            // å°è¯•åœ¨å¥å­è¾¹ç•Œå¤„åˆ†å‰²
            let chunk_end = if end < content.len() {
                content[start..end]
                    .rfind(|c| ['.', '!', '?', '\n'].contains(&c))
                    .map(|pos| start + pos + 1)
                    .unwrap_or(end)
            } else {
                end
            };

            let chunk = content[start..chunk_end].trim().to_string();
            if !chunk.is_empty() {
                chunks.push(chunk);
            }

            start = chunk_end;
            // pb.set_position(start as u64);
        }

        // æ·»åŠ åˆ†å—å¤„ç†å®Œæˆæç¤º
        if chunks.len() > 1 {
            indicatif_println!("âœ… åˆ†å—å®Œæˆï¼Œå…±{}ä¸ªå— (å¹³å‡{}å­—ç¬¦/å—)",
                chunks.len(),
                content.len() / chunks.len());
        }

        Ok(chunks)
    }

    pub fn validate_document(&self, document: &Document) -> Result<()> {
        if document.content.is_empty() {
            return Err(SmartFetchError::ValidationError("æ–‡æ¡£å†…å®¹ä¸ºç©º".to_string()));
        }

        if let Some(max_size_mb) = self.config.max_document_size_mb {
            let max_size_bytes = (max_size_mb * 1024.0 * 1024.0) as usize;
            if document.size_bytes > max_size_bytes {
                return Err(SmartFetchError::ValidationError(format!(
                    "æ–‡æ¡£å¤§å°è¶…è¿‡é™åˆ¶: {}MB > {}MB",
                    document.size_bytes as f64 / (1024.0 * 1024.0),
                    max_size_mb
                )));
            }
        }

        let extension = document.path.extension().and_then(|ext| ext.to_str());
        if let Some(ext) = extension {
            if !self.config.supported_formats.contains(&ext.to_lowercase()) {
                return Err(SmartFetchError::ValidationError(format!(
                    "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {}",
                    ext
                )));
            }
        }

        Ok(())
    }

    pub fn get_document_stats(&self, document: &Document) -> DocumentStats {
        DocumentStats {
            size_bytes: document.size_bytes,
            word_count: document.metadata.word_count,
            line_count: document.metadata.line_count,
            content_type: document.content_type.clone(),
            estimated_tokens: self.estimate_tokens(&document.content),
        }
    }

    pub fn estimate_tokens(&self, content: &str) -> usize {
        // ç®€å•çš„tokenä¼°ç®—ï¼šé€šå¸¸1ä¸ªtoken â‰ˆ 4ä¸ªå­—ç¬¦ï¼ˆè‹±æ–‡ï¼‰æˆ– 1-2ä¸ªæ±‰å­—
        let char_count = content.chars().count();
        char_count / 4
    }
}

#[derive(Debug)]
pub struct DocumentStats {
    pub size_bytes: usize,
    pub word_count: usize,
    pub line_count: usize,
    pub content_type: String,
    pub estimated_tokens: usize,
}
